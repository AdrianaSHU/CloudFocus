{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed699e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ü¶Ö CLOUDFOCUS: \"Fusion-Lite\" Training (FER2013 + RAF-DB Merged)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1Ô∏è‚É£ Setup Environment\n",
    "!pip install -q kaggle\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from google.colab import drive, files\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# ‚ö†Ô∏è FORCE FLOAT32: Prevents \"Flex Delegate\" errors on Raspberry Pi\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "print(\"‚úÖ Policy set to 'float32' (Safe Mode).\")\n",
    "\n",
    "# 2Ô∏è‚É£ Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "CHECKPOINT_DIR = \"/content/drive/MyDrive/FER_Fusion_RAFDB/\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# 3Ô∏è‚É£ Download NEW Dataset (FER2013 + RAF-DB Preprocessed)\n",
    "if not os.path.exists(\"/root/.kaggle/kaggle.json\"):\n",
    "    print(\"\\nüîë Upload kaggle.json:\")\n",
    "    uploaded = files.upload()\n",
    "    !mkdir -p /root/.kaggle\n",
    "    !mv kaggle.json /root/.kaggle/\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "DATASET_PATH = \"/content/fer_rafdb\"\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(\"‚¨áÔ∏è Downloading Merged Dataset...\")\n",
    "    !kaggle datasets download -d fahadullaha/facial-emotion-recognition-dataset -p {DATASET_PATH} --unzip\n",
    "    print(\"‚úÖ Download Complete.\")\n",
    "\n",
    "# Locate the correct folder (The zip might extract into a subfolder)\n",
    "TRAIN_DIR = DATASET_PATH\n",
    "for root, dirs, files in os.walk(DATASET_PATH):\n",
    "    if \"happy\" in dirs and \"angry\" in dirs:\n",
    "        TRAIN_DIR = root\n",
    "        break\n",
    "print(f\"üìÇ Dataset Root: {TRAIN_DIR}\")\n",
    "\n",
    "# 4Ô∏è‚É£ Pipeline Config (224x224 is standard for these models)\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# 5Ô∏è‚É£ Data Loading with Augmentation\n",
    "# We split the single folder into Train (80%) and Validation (20%)\n",
    "print(\"\\nüîÑ Creating Data Pipelines...\")\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Augmentation (Crucial for \"Wild\" datasets)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomBrightness(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Apply augmentation\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "# Get Class Names\n",
    "class_names = train_ds.class_names\n",
    "print(f\"üè∑Ô∏è Classes: {class_names}\")\n",
    "\n",
    "# 6Ô∏è‚É£ The \"Fusion-Lite\" Architecture\n",
    "# Fuses MobileNetV2 (Robust) + MobileNetV3-Small (Efficient)\n",
    "def build_fusion_model():\n",
    "    # Input: Raw RGB 0-255 (Standard for Pi)\n",
    "    inputs = layers.Input(shape=(224, 224, 3), dtype=tf.float32)\n",
    "    \n",
    "    # --- Branch 1: MobileNetV2 (Feature Extraction) ---\n",
    "    # Expects [-1, 1]\n",
    "    x1_norm = layers.Rescaling(1./127.5, offset=-1)(inputs)\n",
    "    base_v2 = applications.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "    base_v2._name = \"mobilenet_v2\"\n",
    "    base_v2.trainable = False\n",
    "    x1 = base_v2(x1_norm)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    \n",
    "    # --- Branch 2: MobileNetV3-Small (The \"Lite\" EfficientNet) ---\n",
    "    # Expects [0, 255] (Handles internal scaling)\n",
    "    base_v3 = applications.MobileNetV3Small(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "    base_v3._name = \"mobilenet_v3\"\n",
    "    base_v3.trainable = False\n",
    "    x2 = base_v3(inputs) # Pass raw inputs\n",
    "    x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    \n",
    "    # --- Fusion ---\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    \n",
    "    # --- Classifier Head ---\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x) # Stronger dropout for better generalization\n",
    "    \n",
    "    outputs = layers.Dense(len(class_names), activation='softmax', dtype='float32')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_fusion_model()\n",
    "print(\"\\nüß† Fusion Model Built.\")\n",
    "\n",
    "# 7Ô∏è‚É£ Training\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(CHECKPOINT_DIR, \"best_fusion_raf.keras\"),\n",
    "    save_best_only=True, monitor='val_accuracy', mode='max'\n",
    ")\n",
    "\n",
    "# Phase 1: Train Head (20 Epochs)\n",
    "print(\"\\nüöÄ Phase 1: Training Head (20 Epochs)...\")\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=20, callbacks=[checkpoint])\n",
    "\n",
    "# Phase 2: Fine-Tuning\n",
    "print(\"\\nüîì Phase 2: Fine-Tuning Base Models...\")\n",
    "for layer in model.layers:\n",
    "    if \"mobilenet\" in layer.name:\n",
    "        layer.trainable = True\n",
    "\n",
    "# Recompile with very low LR for stability\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"üöÄ Phase 2: Deep Training (30 Epochs)...\")\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=[checkpoint])\n",
    "\n",
    "# 8Ô∏è‚É£ Safe TFLite Export (No Flex Ops)\n",
    "print(\"\\n‚öôÔ∏è Exporting Clean Model for Pi...\")\n",
    "\n",
    "# Load best weights\n",
    "model.load_weights(os.path.join(CHECKPOINT_DIR, \"best_fusion_raf.keras\"))\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS] # Strict CPU mode\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "save_path = os.path.join(CHECKPOINT_DIR, \"rafdb_fusion_clean.tflite\")\n",
    "with open(save_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"\\n‚úÖ DONE! Download file: rafdb_fusion_clean.tflite\")\n",
    "print(f\"‚ÑπÔ∏è Put this on your Pi. NO normalization code changes needed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
